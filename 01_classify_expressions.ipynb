{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifying facial expressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Module imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sb\n",
    "\n",
    "# Various components of an ML pipeline\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# For feature engineering\n",
    "from sklearn.decomposition import NMF\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# And finally, a few actual models\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper, reading files\n",
    "def load_features_and_labels(subject, expression, path = \"./data/\"):\n",
    "    \"\"\" Reads the text files of raw data for a specified subject and\n",
    "    expression.\n",
    "    \"\"\"\n",
    "    raw_features = pd.read_table(path + subject + \"_\" + expression + \"_datapoints.txt\",\n",
    "                                 sep=\" \",\n",
    "                                 header=0)\n",
    "    \n",
    "    raw_labels = pd.read_table(path + subject + \"_\" + expression + \"_targets.txt\",\n",
    "                               sep=\" \",\n",
    "                               header=None)\n",
    "    \n",
    "    return raw_features, raw_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## a)  Classify two expressions from subject A using \"off the shelf\" tech\n",
    "\n",
    "NB;  Extra marks for coding my own implementation of the classifier\n",
    "\n",
    "Initial SVM (rbf) parameters taken from https://scikit-learn.org/stable/auto_examples/svm/plot_rbf_parameters.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load and preprocess the data\n",
    "X_train_raw, y_train_raw = load_features_and_labels(\"a\", \"affirmative\")\n",
    "\n",
    "# Drop the timestamp!\n",
    "X_train_raw = X_train_raw.drop('0.0', axis=1)\n",
    "\n",
    "# convert to numpy array for use with sklearn\n",
    "# Y converted to 1D array, not a vector, because sklearn is stupid\n",
    "X_train = np.asarray(X_train_raw)\n",
    "y_train = np.ravel(y_train_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compose SVC pipeline and parameters to search\n",
    "svc_pipeline = Pipeline([('SVM', SVC(kernel=\"linear\"))])\n",
    "svc_parameters = {'SVM__C':np.logspace(-2, 10, 13)}\n",
    "\n",
    "# Set up a cross-validated (10-fold) grid search\n",
    "svc_grid = GridSearchCV(pipeline,\n",
    "                        param_grid = parameters,\n",
    "                        cv=10,\n",
    "                        scoring='f1',\n",
    "                        verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 13 candidates, totalling 130 fits\n"
     ]
    }
   ],
   "source": [
    "# Fit the model!\n",
    "grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Report on performance!\n",
    "grid.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Report in some actually useful detail\n",
    "y_pred = grid.predict(X_train)\n",
    "confusion_matrix(y_train, y_pred)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## b)  Use these classifiers to classify two expressions from subject B\n",
    "NB;  Extra marks for using something beyond simple accuracy (recycle ROC curve code?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## c)  Additional Analysis of classifiers - reverse roles!\n",
    "Train on B, classify A, comment on difference!\n",
    "Try again using a different feature representation (eg; PCA.  Can I think of something better?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## d)  Implement a different classifier\n",
    "Training on single expression, testing (on B?) and extra marks for own implementation\n",
    "Training and testing on a SECOND expression\n",
    "The same by inverting roles\n",
    "Repeating with a different feature representation again!  \n",
    "REF;  for last, try multiclass classifier on principle there should be some shared information?  Data imbalance problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## e)  Wrap-up, compare results of the two classifiers, make comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
