{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Classifying facial expressions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Module imports\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Various performance metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "# Various components of an ML pipeline\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# For feature engineering\n",
    "from sklearn.decomposition import NMF\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.interpolate import interp2d\n",
    "\n",
    "# And a few actual models\n",
    "from sklearn.svm import LinearSVC    #  For q's a, b and c\n",
    "from xgboost import XGBClassifier    #  For the FUN part d\n",
    "\n",
    "# plotting utilities\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions!\n",
    "def load_features_and_labels(subject, expression, path = \"./data/\"):\n",
    "    \"\"\" Reads the text files of raw data for a specified subject and\n",
    "    expression.  Also removes the timestamp column and converts to\n",
    "    numpy arrays for sklearn compatibility.\n",
    "    \"\"\"\n",
    "    raw_features = pd.read_table(path + subject + \"_\" + expression + \"_datapoints.txt\",\n",
    "                                 sep=\" \",\n",
    "                                 header=0)\n",
    "    \n",
    "    # Drop the timestamp!\n",
    "    raw_features = raw_features.drop('0.0', axis=1)\n",
    "    \n",
    "    raw_labels = pd.read_table(path + subject + \"_\" + expression + \"_targets.txt\",\n",
    "                               sep=\" \",\n",
    "                               header=None)\n",
    "    \n",
    "    # Transform to numpy arrays\n",
    "    return np.asarray(raw_features), np.ravel(raw_labels)\n",
    "\n",
    "\n",
    "def make_measurements(true, predicted):\n",
    "    \"\"\" Make and report on lots of measurements of ML performance\n",
    "    metrics.\n",
    "    \"\"\"\n",
    "    f1 = f1_score(true, predicted)\n",
    "    precision = precision_score(true, predicted)\n",
    "    recall = recall_score(true, predicted)\n",
    "    return(\"F1: {:.2f}, precision: {:.2f}, recall: {:.2f}\".format(f1, precision, recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code adapted from <https://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html>\n",
    "def plot_confusion_matrix(y_true, y_pred,\n",
    "                          normalize=False,\n",
    "                          title=None,\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if not title:\n",
    "        if normalize:\n",
    "            title = 'Normalized confusion matrix'\n",
    "        else:\n",
    "            title = 'Confusion matrix, without normalization'\n",
    "\n",
    "    # Compute confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    \n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    ax.figure.colorbar(im, ax=ax)\n",
    "    # We want to show all ticks...\n",
    "    ax.set(xticks=np.arange(cm.shape[1]),\n",
    "           yticks=np.arange(cm.shape[0]),\n",
    "           title=title,\n",
    "           ylabel='True label',\n",
    "           xlabel='Predicted label')\n",
    "\n",
    "    # Loop over data dimensions and create text annotations.\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            ax.text(j, i, format(cm[i, j], fmt),\n",
    "                    ha=\"center\", va=\"center\",\n",
    "                    color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    fig.tight_layout()\n",
    "    return ax\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# a & b)  Classify two expressions from subject A using \"off the shelf\" tech\n",
    "\n",
    "NB;  Extra marks for coding my own implementation of the classifier\n",
    "\n",
    "Initial SVM (rbf) parameters taken as suggested from https://scikit-learn.org/stable/auto_examples/svm/plot_rbf_parameters.html\n",
    "\n",
    "Use these classifiers to classify two expressions from subject B.\n",
    "\n",
    "NB;  Extra marks for using something beyond simple accuracy (recycle ROC curve code?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the model we're going to use for sections a, b and c\n",
    "def setup_svc(cv=10,\n",
    "              pipe_list = [('SVM', LinearSVC())],\n",
    "              svc_parameters = {'SVM__C':np.logspace(-2, 10, 13)}):\n",
    "    \"\"\" Helper function.  Lots of bits for setting up a grid-search\n",
    "    for a linear SVM.\n",
    "    \"\"\"\n",
    "    svc_pipeline = Pipeline(pipe_list)\n",
    "\n",
    "    # Set up a cross-validated grid search\n",
    "    svc_grid = GridSearchCV(svc_pipeline,                # tasks to perform\n",
    "                            param_grid = svc_parameters, # parameters to try\n",
    "                            cv=cv,                       # num cv folds\n",
    "                            scoring='f1',                # score on f1\n",
    "                            n_jobs=-1,                   # use all processors in parallel\n",
    "                            verbose=True)\n",
    "    \n",
    "    return(svc_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifying \"doubt\" expression\n",
    "\n",
    "This expression was chosen because in the original paper their own classification pipeline performed really well on it (f1 of 0.88 , precision of 0.94 and recall of 0.76 classifying single frames independently, engineered features WITHOUT depth features)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load and preprocess the data\n",
    "X_A_doubt, y_A_doubt = load_features_and_labels(\"a\", \"doubt_question\")\n",
    "X_B_doubt, y_B_doubt = load_features_and_labels(\"b\", \"doubt_question\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 13 candidates, totalling 130 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   12.4s\n",
      "[Parallel(n_jobs=-1)]: Done 130 out of 130 | elapsed:   39.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'SVM__C': 1000.0}\n",
      "Score:  0.8530718222740078\n"
     ]
    }
   ],
   "source": [
    "random.seed(42)\n",
    "\n",
    "# Model defined at start of section\n",
    "svc_grid = setup_svc()\n",
    "\n",
    "# Fit the model!\n",
    "svc_grid.fit(X_A_doubt, y_A_doubt)\n",
    "\n",
    "# What hyper-parameter combination was chosen?\n",
    "print(svc_grid.best_params_)\n",
    "\n",
    "# Report on performance!\n",
    "print(\"Score: \", svc_grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'make_measurements' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-8a61c6bfd058>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Report performance against the training data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0my_A_doubt_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msvc_grid\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_A_doubt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mmake_measurements\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_A_doubt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_A_doubt_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'make_measurements' is not defined"
     ]
    }
   ],
   "source": [
    "# Report performance against the training data\n",
    "y_A_doubt_pred = svc_grid.predict(X_A_doubt)\n",
    "make_measurements(y_A_doubt, y_A_doubt_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(y_A_doubt, y_A_doubt_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting the \"doubt\" expression for subject B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Report performance against unseen test data\n",
    "y_B_doubt_pred = svc_grid.predict(X_B_doubt)\n",
    "make_measurements(y_B_doubt, y_B_doubt_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_confusion_matrix(y_B_doubt, y_B_doubt_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifying \"negative\" expression\n",
    "\n",
    "The original author's model performed poorly on this one (f1 score of 0.44, precision of 0.33, recall of 0.66), so after the apparently easier problem of classifying doubt this should give us our relative performance on a hard problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load and preprocess the data\n",
    "X_A_neg, y_A_neg = load_features_and_labels(\"a\", \"negative\")\n",
    "X_B_neg, y_B_neg = load_features_and_labels(\"b\", \"negative\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "random.seed(42)\n",
    "\n",
    "# model defined at start of section\n",
    "svc_grid = setup_svc()\n",
    "\n",
    "# Fit the model!\n",
    "svc_grid.fit(X_A_neg, y_A_neg)\n",
    "\n",
    "# What hyper-parameter combination was chosen?\n",
    "print(svc_grid.best_params_)\n",
    "\n",
    "# Report on performance!\n",
    "print(\"Score: \", svc_grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Report performance against the training data\n",
    "y_A_neg_pred = svc_grid.predict(X_A_neg)\n",
    "make_measurements(y_A_neg, y_A_neg_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_confusion_matrix(y_A_neg, y_A_neg_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting the \"negative\" expression for subject B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Report performance against unseen test data\n",
    "y_B_neg_pred = svc_grid.predict(X_B_neg)\n",
    "make_measurements(y_B_neg, y_B_neg_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_confusion_matrix(y_B_neg, y_B_neg_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# c)  Additional Analysis of classifiers - reverse roles!\n",
    "Train on B, classify A, comment on difference!\n",
    "Try again using a different feature representation (eg; PCA.  Can I think of something better?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifying \"doubt\" expression in REVERSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "random.seed(42)\n",
    "\n",
    "# Model defined at start of section\n",
    "svc_grid = setup_svc()\n",
    "\n",
    "# Fit the model!\n",
    "svc_grid.fit(X_B_doubt, y_B_doubt)\n",
    "\n",
    "# What hyper-parameter combination was chosen?\n",
    "print(svc_grid.best_params_)\n",
    "\n",
    "# Report on performance!\n",
    "print(\"Score: \", svc_grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Report performance against the training data\n",
    "y_B_doubt_pred = svc_grid.predict(X_B_doubt)\n",
    "make_measurements(y_B_doubt, y_B_doubt_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(y_B_doubt, y_B_doubt_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting the \"doubt\" expression for subject A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Report performance against unseen test data\n",
    "y_A_doubt_pred = svc_grid.predict(X_A_doubt)\n",
    "make_measurements(y_A_doubt, y_A_doubt_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_confusion_matrix(y_A_doubt, y_A_doubt_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifying \"negative\" expression in REVERSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(42)\n",
    "\n",
    "# model defined at start of section\n",
    "svc_grid = setup_svc()\n",
    "\n",
    "# Fit the model!\n",
    "svc_grid.fit(X_B_neg, y_B_neg)\n",
    "\n",
    "# What hyper-parameter combination was chosen?\n",
    "print(svc_grid.best_params_)\n",
    "\n",
    "# Report on performance!\n",
    "print(\"Score: \", svc_grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Report performance against unseen test data\n",
    "y_B_neg_pred = svc_grid.predict(X_B_neg)\n",
    "make_measurements(y_B_neg, y_B_neg_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(y_B_neg, y_B_neg_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting the \"negative\" expression for Subject A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Report performance against unseen test data\n",
    "y_B_neg_pred = svc_grid.predict(X_A_neg)\n",
    "make_measurements(y_A_neg, y_A_neg_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_confusion_matrix(y_A_neg, y_A_neg_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trying a new data representation - independent scaling\n",
    "\n",
    "This is cheating a little - I'm not changing the feature representation much, but it addresses an important issue in this dataset in an appropriate way.\n",
    "\n",
    "A model trained on one user doesn't translate well to another.  This could well be because the model currently depends on absolute positions of features that may be quite different for different people's faces or poses.  To fix this, rather than try anything clever like PCA I'm simply going to independently scale every feature for subject A and subject B.  I'll try something clever in the next section, I promise.\n",
    "\n",
    "It's independent for each subject. The assumptions made are that this will help the model pick out the range of movement of features rather than their absolute positions, and that the same features will move in the same way for different subjects."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifying \"doubt\" expression using scaled features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and preprocess the data\n",
    "X_A_doubt, y_A_doubt = load_features_and_labels(\"a\", \"doubt_question\")\n",
    "X_B_doubt, y_B_doubt = load_features_and_labels(\"b\", \"doubt_question\")\n",
    "\n",
    "# Load and preprocess the data\n",
    "X_A_neg, y_A_neg = load_features_and_labels(\"a\", \"negative\")\n",
    "X_B_neg, y_B_neg = load_features_and_labels(\"b\", \"negative\")\n",
    "\n",
    "# Scale all features\n",
    "scaler = StandardScaler()\n",
    "X_A_doubt_s = scaler.fit(X_A_doubt).transform(X_A_doubt)\n",
    "X_B_doubt_s = scaler.fit(X_B_doubt).transform(X_B_doubt)\n",
    "X_A_neg_s = scaler.fit(X_A_neg).transform(X_A_neg)\n",
    "X_B_neg_s = scaler.fit(X_B_neg).transform(X_B_neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "random.seed(42)\n",
    "\n",
    "# Model defined at start of section\n",
    "svc_grid = setup_svc()\n",
    "\n",
    "# Fit the model!\n",
    "svc_grid.fit(X_A_doubt_s, y_A_doubt)\n",
    "\n",
    "# What hyper-parameter combination was chosen?\n",
    "print(svc_grid.best_params_)\n",
    "\n",
    "# Report on performance!\n",
    "print(\"Score: \", svc_grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Report performance against the training data\n",
    "y_A_doubt_pred = svc_grid.predict(X_A_doubt)\n",
    "make_measurements(y_A_doubt, y_A_doubt_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(y_A_doubt, y_A_doubt_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting the \"doubt\" expression for subject B using scaled features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Report performance against unseen test data\n",
    "y_B_doubt_pred = svc_grid.predict(X_B_doubt_s)\n",
    "make_measurements(y_B_doubt, y_B_doubt_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_confusion_matrix(y_B_doubt, y_B_doubt_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifying \"negative\" expression using scaled features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "random.seed(42)\n",
    "\n",
    "# model defined at start of section\n",
    "svc_grid = setup_svc()\n",
    "\n",
    "# Fit the model!\n",
    "svc_grid.fit(X_A_neg_s, y_A_neg)\n",
    "\n",
    "# What hyper-parameter combination was chosen?\n",
    "print(svc_grid.best_params_)\n",
    "\n",
    "# Report on performance!\n",
    "print(\"Score: \", svc_grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Report performance against the training data\n",
    "y_A_neg_pred = svc_grid.predict(X_A_neg_s)\n",
    "make_measurements(y_A_neg, y_A_neg_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_confusion_matrix(y_A_neg, y_A_neg_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting the \"negative\" expression for subject B using scaled features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Report performance against unseen test data\n",
    "y_B_neg_pred = svc_grid.predict(X_B_neg_s)\n",
    "make_measurements(y_B_neg, y_B_neg_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_confusion_matrix(y_B_neg, y_B_neg_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# d)  pt1 - Implement a different classifier\n",
    "\n",
    "Training on single expression, testing (on B?) and extra marks for own implementation\n",
    "Training and testing on a SECOND expression.\n",
    "The same by inverting roles\n",
    "Repeating with a different feature representation again!  \n",
    "REF;  for last, try multiclass classifier on principle there should be some shared information?  Data imbalance problem\n",
    "\n",
    "For this, because I'm getting bored, we're going to skip a few steps.  I'm going to train a Gradient Boosted Trees algorithm on the \"doubts\" question subject A, evaluate on B, and then I'm going to implement NNMF and see how that improves things.  I'll invert roles if I feel like it, I'm feeling bored of that game after 12 confusion matrices so far.\n",
    "\n",
    "I'm maintaining independent scaling of subject's features since it was so useful in the last step too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the model we're going to use for section d.\n",
    "def setup_gbt(cv=10,\n",
    "              pipe_list = [('GBT', XGBClassifier(n_estimators=300))],\n",
    "              gbt_parameters = {'GBT__max_depth':range(2, 11)}):\n",
    "    \"\"\" Helper function.  Lots of bits for setting up a grid-search\n",
    "    for gbt.\n",
    "    \"\"\"\n",
    "    gbt_pipeline = Pipeline(pipe_list)\n",
    "\n",
    "    # Set up a cross-validated grid search\n",
    "    gbt_grid = GridSearchCV(gbt_pipeline,                # tasks to perform\n",
    "                            param_grid = gbt_parameters, # parameters to try\n",
    "                            cv=cv,                       # num cv folds\n",
    "                            scoring='f1',          # score on accuracy\n",
    "                            n_jobs=-1,                   # use all processors in parallel\n",
    "                            verbose=True)\n",
    "    \n",
    "    return(gbt_grid)\n",
    "\n",
    "# This is the model we're going to use for section d.\n",
    "# Fun fact:  If each pipeline component doesn't have at least\n",
    "# one named argument this fails for no good reason!\n",
    "def setup_gbt_nmf(cv=10,\n",
    "                  pipe_list = [('NMF', NMF(solver=\"cd\")),\n",
    "                               ('GBT', XGBClassifier(n_estimators=300))],\n",
    "                  gbt_parameters = {'GBT__max_depth':range(2, 11),\n",
    "                                    'NMF__n_components':[26, 28, 29, 30, 31, 32, 34, 36]}):\n",
    "    \"\"\" Helper function.  Lots of bits for setting up a grid-search\n",
    "    for gbt.\n",
    "    \"\"\"\n",
    "    gbt_pipeline = Pipeline(pipe_list)\n",
    "\n",
    "    # Set up a cross-validated grid search\n",
    "    gbt_grid = GridSearchCV(gbt_pipeline,                # tasks to perform\n",
    "                            param_grid = gbt_parameters, # parameters to try\n",
    "                            cv=cv,                       # num cv folds\n",
    "                            scoring='f1',          # score on accuracy\n",
    "                            n_jobs=-1,                   # use all processors in parallel\n",
    "                            verbose=True)\n",
    "    \n",
    "    return(gbt_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and preprocess the data\n",
    "X_A_doubt, y_A_doubt = load_features_and_labels(\"a\", \"doubt_question\")\n",
    "X_B_doubt, y_B_doubt = load_features_and_labels(\"b\", \"doubt_question\")\n",
    "\n",
    "# Load and preprocess the data\n",
    "X_A_neg, y_A_neg = load_features_and_labels(\"a\", \"negative\")\n",
    "X_B_neg, y_B_neg = load_features_and_labels(\"b\", \"negative\")\n",
    "\n",
    "# Scale all features\n",
    "scaler = StandardScaler()\n",
    "X_A_doubt_s = scaler.fit(X_A_doubt).transform(X_A_doubt)\n",
    "X_B_doubt_s = scaler.fit(X_B_doubt).transform(X_B_doubt)\n",
    "X_A_neg_s = scaler.fit(X_A_neg).transform(X_A_neg)\n",
    "X_B_neg_s = scaler.fit(X_B_neg).transform(X_B_neg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifying the \"doubt\" expression using subject A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(42)\n",
    "\n",
    "# model defined at start of section\n",
    "gbt_grid = setup_gbt()\n",
    "\n",
    "# Fit the model!\n",
    "gbt_grid.fit(X_A_doubt_s, y_A_doubt)\n",
    "\n",
    "# What hyper-parameter combination was chosen?\n",
    "print(gbt_grid.best_params_)\n",
    "\n",
    "# Report on performance!\n",
    "print(\"Score: \", gbt_grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Report performance against the training data\n",
    "y_A_doubt_pred = gbt_grid.predict(X_A_doubt_s)\n",
    "make_measurements(y_A_doubt, y_A_doubt_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_confusion_matrix(y_A_doubt, y_A_doubt_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting the \"doubt\" expression for subject B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Report performance against unseen test data\n",
    "y_B_doubt_pred = gbt_grid.predict(X_B_doubt_s)\n",
    "make_measurements(y_B_doubt, y_B_doubt_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_confusion_matrix(y_B_doubt, y_B_doubt_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifying the \"negative\" expression using subject A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(42)\n",
    "\n",
    "# model defined at start of section\n",
    "gbt_grid = setup_gbt()\n",
    "\n",
    "# Fit the model!\n",
    "gbt_grid.fit(X_A_neg_s, y_A_neg)\n",
    "\n",
    "# What hyper-parameter combination was chosen?\n",
    "print(gbt_grid.best_params_)\n",
    "\n",
    "# Report on performance!\n",
    "print(\"Score: \", gbt_grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Report performance against the training data\n",
    "y_A_neg_pred = gbt_grid.predict(X_A_neg_s)\n",
    "make_measurements(y_A_neg, y_A_neg_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_confusion_matrix(y_A_neg, y_A_neg_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting the \"negative\" expression for subject B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Report performance against unseen test data\n",
    "y_B_neg_pred = gbt_grid.predict(X_B_neg_s)\n",
    "make_measurements(y_B_neg, y_B_neg_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_confusion_matrix(y_B_neg, y_B_neg_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# d) pt2 - XGBoost applied to Non-Negative Matrix Factorisation (NMF) representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and preprocess the data\n",
    "X_A_doubt, y_A_doubt = load_features_and_labels(\"a\", \"doubt_question\")\n",
    "X_B_doubt, y_B_doubt = load_features_and_labels(\"b\", \"doubt_question\")\n",
    "\n",
    "# Load and preprocess the data\n",
    "X_A_neg, y_A_neg = load_features_and_labels(\"a\", \"negative\")\n",
    "X_B_neg, y_B_neg = load_features_and_labels(\"b\", \"negative\")\n",
    "\n",
    "# Scale all features\n",
    "scaler = StandardScaler()\n",
    "X_A_doubt_s = scaler.fit(X_A_doubt).transform(X_A_doubt)\n",
    "X_B_doubt_s = scaler.fit(X_B_doubt).transform(X_B_doubt)\n",
    "X_A_neg_s = scaler.fit(X_A_neg).transform(X_A_neg)\n",
    "X_B_neg_s = scaler.fit(X_B_neg).transform(X_B_neg)\n",
    "\n",
    "# Shift_Factor\n",
    "shift_factor_doubt = min(np.min(X_A_doubt_s), np.min(X_B_doubt_s))\n",
    "X_A_doubt_s -= shift_factor_doubt\n",
    "X_B_doubt_s -= shift_factor_doubt\n",
    "\n",
    "shift_factor_neg = min(np.min(X_A_neg_s), np.min(X_B_neg_s))\n",
    "X_A_neg_s -= shift_factor_neg\n",
    "X_B_neg_s -= shift_factor_neg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifying the \"doubt\" expression using subject A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(42)\n",
    "\n",
    "# model defined at start of section\n",
    "gbt_grid = setup_gbt_nmf()\n",
    "\n",
    "# Fit the model!\n",
    "gbt_grid.fit(X_A_doubt_s, y_A_doubt)\n",
    "\n",
    "# What hyper-parameter combination was chosen?\n",
    "print(gbt_grid.best_params_)\n",
    "\n",
    "# Report on performance!\n",
    "print(\"Score: \", gbt_grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Report performance against the training data\n",
    "y_A_doubt_pred = gbt_grid.predict(X_A_doubt_s)\n",
    "make_measurements(y_A_doubt, y_A_doubt_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_confusion_matrix(y_A_doubt, y_A_doubt_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting the \"doubt\" expression for subject B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Report performance against unseen test data\n",
    "y_B_doubt_pred = gbt_grid.predict(X_B_doubt_s)\n",
    "make_measurements(y_B_doubt, y_B_doubt_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_confusion_matrix(y_B_doubt, y_B_doubt_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifying the \"negative\" expression using subject A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(42)\n",
    "\n",
    "# model defined at start of section\n",
    "gbt_grid = setup_gbt_nmf()\n",
    "\n",
    "# Fit the model!\n",
    "gbt_grid.fit(X_A_neg_s, y_A_neg)\n",
    "\n",
    "# What hyper-parameter combination was chosen?\n",
    "print(gbt_grid.best_params_)\n",
    "\n",
    "# Report on performance!\n",
    "print(\"Score: \", gbt_grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Report performance against the training data\n",
    "y_A_neg_pred = gbt_grid.predict(X_A_neg_s)\n",
    "make_measurements(y_A_neg, y_A_neg_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_confusion_matrix(y_A_neg, y_A_neg_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting the \"negative\" expression for subject B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Report performance against unseen test data\n",
    "y_B_neg_pred = gbt_grid.predict(X_B_neg_s)\n",
    "make_measurements(y_B_neg, y_B_neg_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_confusion_matrix(y_B_neg, y_B_neg_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# e)  Wrap-up, compare results of the two classifiers, make comments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scratch-space\n",
    "\n",
    "Note:  Data augmentation requires reshuffling of data, can't rely on cross-val otherwise!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "These results without augmentation\n",
    "\n",
    "- With NMF(30): 'F1: 0.85, precision: 0.83, recall: 0.87'\n",
    "- With NMF(31): 'F1: 0.84, precision: 0.84, recall: 0.85'\n",
    "- Without NMF:  'F1: 0.84, precision: 0.83, recall: 0.87'\n",
    "- With PCA(45): 'F1: 0.82, precision: 0.82, recall: 0.82'\n",
    "- With PCA(48): 'F1: 0.83, precision: 0.79, recall: 0.87'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MAD SCIENCE! - data augmentation instead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data_dimensions(data):\n",
    "    \"\"\" Extract X, Y and Z coordinates from these feature sets.\"\"\"\n",
    "    X = np.asarray( [[x[i] for i in range(0, 300, 3)] for x in data] )\n",
    "    Y = np.asarray( [[x[i] for i in range(1, 300, 3)] for x in data] )\n",
    "    Z = np.asarray( [[x[i] for i in range(2, 300, 3)] for x in data] )\n",
    "    return(X, Y, Z)\n",
    "\n",
    "\n",
    "def generate_skewed_samples(X, Y, factor=0.2, fold=1):\n",
    "    \"\"\" Take X and Y data and skew them randomly, sample by sample. \n",
    "    Create as many folds (multiples of original dataset size).\n",
    "    \"\"\"\n",
    "    \n",
    "    # Create a set of X and Y coordinates for the frame corners\n",
    "    x_coords = [np.min(X), np.min(X), np.max(X), np.max(X)]\n",
    "    y_coords = [np.min(Y), np.max(Y), np.min(Y), np.max(Y)]\n",
    "    \n",
    "    new_X = []\n",
    "    new_Y = []\n",
    "    \n",
    "    # For (as many times original data as we want)\n",
    "    for repeats in range(fold):\n",
    "        for i in range(len(X)):\n",
    "            \n",
    "            # Create the four interpolation points with random uniform\n",
    "            x_skewed = [x + (x_coords[-1]-x_coords[0]) * np.random.uniform(-1, 1) * factor for x in x_coords]\n",
    "            y_skewed = [y + (y_coords[-1]-y_coords[0]) *np.random.uniform(-1, 1) * factor for y in y_coords]\n",
    "            \n",
    "            # create the interpolators\n",
    "            fx = interp2d(x=x_coords, y=y_coords, z=x_skewed, kind=\"linear\")\n",
    "            fy = interp2d(x=x_coords, y=y_coords, z=y_skewed, kind=\"linear\")\n",
    "            \n",
    "            # Alter all points for a given sample using the same interpolator\n",
    "            new_X.append([float(fx(X[i, j], Y[i, j])) for j in range(X.shape[1])])\n",
    "            new_Y.append([float(fy(X[i, j], Y[i, j])) for j in range(X.shape[1])])\n",
    "        \n",
    "    return(np.asarray(new_X), np.asarray(new_Y))\n",
    "\n",
    "\n",
    "def create_augmented_dataset(data, fold=3):\n",
    "    \"\"\" Take a dataset, extract the X and Y coordinates only, and\n",
    "    augment through random skewing/shearing/jittering (simultaneous).\n",
    "    \n",
    "    Return the original data with augmented data appended.\n",
    "    \"\"\"\n",
    "    # Extract just the X and Y variables\n",
    "    X, Y, Z = split_data_dimensions(data)\n",
    "    \n",
    "    # Generate multiple randomly skewed versions (on X and Y only though)\n",
    "    new_X, new_Y = generate_skewed_samples(X, Y, fold=fold)\n",
    "    \n",
    "    # Join original and skewed data into new dataset\n",
    "    all_X = np.concatenate((X, new_X))\n",
    "    all_Y = np.concatenate((Y, new_Y))\n",
    "    #all_Z = np.concatenate([Z for i in range(fold+1)])\n",
    "    \n",
    "    # Join into row-wise samples\n",
    "    return(np.concatenate((all_X, all_Y), axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and preprocess the data (doubt)\n",
    "X_A_doubt, y_A_doubt = load_features_and_labels(\"a\", \"doubt_question\")\n",
    "X_B_doubt, y_B_doubt = load_features_and_labels(\"b\", \"doubt_question\")\n",
    "\n",
    "# Load and preprocess the data (negative)\n",
    "X_A_neg, y_A_neg = load_features_and_labels(\"a\", \"negative\")\n",
    "X_B_neg, y_B_neg = load_features_and_labels(\"b\", \"negative\")\n",
    "\n",
    "# Scale all features\n",
    "scaler = StandardScaler()\n",
    "X_A_doubt_s = scaler.fit(X_A_doubt).transform(X_A_doubt)\n",
    "X_B_doubt_s = scaler.fit(X_B_doubt).transform(X_B_doubt)\n",
    "X_A_neg_s = scaler.fit(X_A_neg).transform(X_A_neg)\n",
    "X_B_neg_s = scaler.fit(X_B_neg).transform(X_B_neg)\n",
    "\n",
    "# Augment the training datasets four-fold\n",
    "folds = 4\n",
    "X_A_doubt_s = create_augmented_dataset(X_A_doubt_s, fold=folds)\n",
    "X_A_neg_s = create_augmented_dataset(X_A_neg_s, fold=folds)\n",
    "\n",
    "# Extend the training classifications\n",
    "y_A_doubt = np.concatenate([y_A_doubt for i in range(folds+1)])\n",
    "y_A_neg = np.concatenate([y_A_neg for i in range(folds+1)])\n",
    "\n",
    "random.seed(42)\n",
    "\n",
    "# Randomly shuffle the training data\n",
    "permutation_doubt = np.random.permutation(X_A_doubt_s.shape[0])\n",
    "X_A_doubt_s = X_A_doubt_s[permutation_doubt]\n",
    "y_A_doubt = y_A_doubt[permutation_doubt]\n",
    "permutation_neg = np.random.permutation(X_A_neg_s.shape[0])\n",
    "X_A_neg_s = X_A_doubt_s[permutation_neg]\n",
    "y_A_neg = y_A_doubt[permutation_neg]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifying the \"doubt\" expression using subject A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(42)\n",
    "\n",
    "# model defined at start of section\n",
    "gbt_grid = setup_gbt()\n",
    "\n",
    "# Fit the model!\n",
    "gbt_grid.fit(X_A_doubt_s, y_A_doubt)\n",
    "\n",
    "# What hyper-parameter combination was chosen?\n",
    "print(gbt_grid.best_params_)\n",
    "\n",
    "# Report on performance!\n",
    "print(\"Score: \", gbt_grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Report performance against the training data\n",
    "y_A_doubt_pred = gbt_grid.predict(X_A_doubt_s)\n",
    "make_measurements(y_A_doubt, y_A_doubt_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_confusion_matrix(y_A_doubt, y_A_doubt_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting the \"doubt\" expression for subject B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Report performance against unseen test data\n",
    "X, Y, Z = split_data_dimensions(X_B_doubt_s)\n",
    "X_B_doubt_s = np.concatenate((X, Y), axis=1)\n",
    "y_B_doubt_pred = gbt_grid.predict(X_B_doubt_s)\n",
    "make_measurements(y_B_doubt, y_B_doubt_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_confusion_matrix(y_B_doubt, y_B_doubt_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifying the \"negative\" expression using subject A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(42)\n",
    "\n",
    "# model defined at start of section\n",
    "gbt_grid = setup_gbt()\n",
    "\n",
    "# Fit the model!\n",
    "gbt_grid.fit(X_A_neg_s, y_A_neg)\n",
    "\n",
    "# What hyper-parameter combination was chosen?\n",
    "print(gbt_grid.best_params_)\n",
    "\n",
    "# Report on performance!\n",
    "print(\"Score: \", gbt_grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Report performance against the training data\n",
    "y_A_neg_pred = gbt_grid.predict(X_A_neg_s)\n",
    "make_measurements(y_A_neg, y_A_neg_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_confusion_matrix(y_A_neg, y_A_neg_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting the \"negative\" expression for subject B\n",
    "\n",
    "- With augmentation: 'F1: 0.62/0.55, precision: 0.54, recall: 0.72'\n",
    "- With Z removed:    'F1: 0.55, precision: 0.48, recall: 0.65'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Report performance against unseen test data\n",
    "X, Y, Z = split_data_dimensions(X_B_neg_s)\n",
    "X_B_neg_s = np.concatenate((X, Y), axis=1)\n",
    "y_B_neg_pred = gbt_grid.predict(X_B_neg_s)\n",
    "make_measurements(y_B_neg, y_B_neg_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_confusion_matrix(y_B_neg, y_B_neg_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
